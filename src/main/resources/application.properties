

server.port=8924
fxft.jdbc.debug=true
management.endpoints.web.exposure.include=refresh,health,info,mappings,metrics
management.endpoint.health.show-details=always
management.endpoint.metrics.enabled=true
management.endpoint.metrics.cache.time-to-live=2ms
spring.servlet.multipart.max-file-size=100MB
spring.servlet.multipart.max-request-size=1000MB
spring.main.allow-bean-definition-overriding=true
name=111

yrgpstranspondEnabled=true
hzz.refresh-value.checkInterval=30
hzz.refresh-value.enabled=true
#这个是默认的数据库
spring.datasource.driverClassName=com.mysql.jdbc.Driver
spring.datasource.url=jdbc:mysql://127.0.0.1:3306/hzzdata?serverTimezone=GMT%2B8&useUnicode=true&characterEncoding=utf-8
spring.datasource.username=root
spring.datasource.password=

#加入模板引擎
spring.thymeleaf.prefix=classpath:/webhtml/

#开启feign支持hystrix  (注意，一定要开启，旧版本默认支持，新版本默认关闭)
# #修改调用超时时间（默认是1秒就算超时）
feign.hystrix.enabled=true

#这边是mybatis正规的配置
#mybatis.type-aliases-package=com.hzz.hzzcloud.freemarker.main.maparea.entity
#mybatis.mapper-locations= classpath:mybatis_mysql/*.xml
#
#spring.datasource.driverClassName=com.mysql.jdbc.Driver
#spring.datasource.url=jdbc:mysql://172.16.8.96:3306/subiaodb?autoReconnect=true&characterEncoding=utf-8&zeroDateTimeBehavior=convertToNull&rewriteBatchedStatements=true&useSSL=false
#spring.datasource.username=ascs
#spring.datasource.password=96bcnJ6ifCz7NBHpjhB1ZA45


## Redis服务器地址
#fxft.redis.host=172.16.8.96
## Redis服务器连接端口
#fxft.redis.port=6379
## Redis服务器连接密码（默认为空）
#fxft.redis.password=46qUdp1mH1AM8RNS3TVsfNkQ
## 连接池最大连接数（使用负值表示没有限制）
#fxft.redis.max-total=200
## 连接池最大阻塞等待时间（使用负值表示没有限制）
#fxft.redis.max-wait=-1
## 连接池中的最大空闲连接
#fxft.redis.max-idle=200
## 连接池中的最小空闲连接
#fxft.redis.min-idle=0
## 连接超时时间（毫秒）
#fxft.redis.timeout=0
## 连接的库序号
#fxft.redis.select=1


#
#spring.datasource.driverClassName=com.mysql.jdbc.Driver
#spring.datasource.url=jdbc:mysql://127.0.0.1:3306/jfinal_demo?serverTimezone=GMT%2B8&useUnicode=true&characterEncoding=utf-8
#spring.datasource.username=root
#spring.datasource.password=
#
#
## Hikari will use the above plus the following to setup connection pooling
#spring.datasource.type=com.zaxxer.hikari.HikariDataSource
#spring.datasource.hikari.minimum-idle=5
#spring.datasource.hikari.maximum-pool-size=10
#spring.datasource.hikari.auto-commit=true
#spring.datasource.hikari.idle-timeout=300
#spring.datasource.hikari.pool-name=DatebookHikariCP
#spring.datasource.hikari.max-lifetime=180
#spring.datasource.hikari.connection-timeout=300
#spring.datasource.hikari.validationTimeout=300
#spring.datasource.hikari.connection-test-query=SELECT 1



# mybatis config
#mybatis.mapper-locations=classpath:mybatis/mapper/*.xml
#mybatis.configuration.map-underscore-to-camel-case=true
#mybatis.configuration.call-setters-on-nulls=true


#server.port=2005
#unit.type=SerReport
#unit.profile=
#
#kafkaComsumer.threadPool=10

##????
##spring.activemq.broker-url=tcp://127.0.0.1:61616
##????
#spring.activemq.broker-url=tcp://172.30.102.21:61616
#spring.jms.pub-sub-domain=true
#
#activemq.vehicleChangeTopic=vehicleTopic
#activemq.terminalChangeTopic=terminalTopic
#
##============== kafka ===================
## ???kafka ??????????????
##spring.kafka.bootstrap-servers=172.30.101.227:9092
#spring.kafka.bootstrap-servers=112.124.202.93:9092
#
##=============== provider  =======================
#spring.kafka.producer.retries=0
## ????????????????????
#spring.kafka.producer.batch-size=16384
#spring.kafka.producer.buffer-memory=33554432
## ??????key?????????????
#spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.ByteArraySerializer
#
##=============== consumer  =======================
## ????????????group id
#spring.kafka.consumer.group-id=cid_report
#spring.kafka.consumer.auto-offset-reset=latest
#spring.kafka.consumer.enable-auto-commit=true
#spring.kafka.consumer.auto-commit-interval=100
#spring.kafka.consumer.max-poll-records=20971520
## ??????key?????????????
#spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.ByteArrayDeserializer
##=======set comsumer max fetch.byte 2*1024*1024=============












